# Instruction Tuning Datasets
All available datasets for Instruction Tuning of Large Language Models

### Gold standard datasets (Originally meant for multi-task tuning)
- P3: https://github.com/bigscience-workshop/promptsource, https://huggingface.co/datasets/bigscience/P3
  - Collection of prompted English datasets covering a diverse set of NLP tasks
  - 2000 prompt types over 270 datasets
- Natural Instructions v2: https://github.com/allenai/natural-instructions
  - A benchmark of 1,616 diverse NLP tasks and their expert-written instructions, covering 76 distinct task types and 55 different languages.
- The Flan Collection: https://github.com/google-research/FLAN/tree/main/flan/v2 
  - superset of some of the datasets here
  -  1836 Tasks, 15m examples 
- CrossFit: https://github.com/INK-USC/CrossFit
- ExMix: https://arxiv.org/abs/2111.10952



### Generated using GPT 3.5/4

- Self-Instruct: https://github.com/yizhongw/self-instruct
- Unnatural Instructions: https://github.com/orhonovich/unnatural-instructions
- Alpaca: https://huggingface.co/datasets/tatsu-lab/alpaca
- Alpaca-Clean: https://github.com/gururise/AlpacaDataCleaned
- AlpacaGPT3.5Customized: https://huggingface.co/datasets/whitefox44/AlpacaGPT3.5Customized
- GPT4All: https://github.com/nomic-ai/gpt4all
- ShareGPT: https://huggingface.co/datasets/RyokoAI/ShareGPT52K
- GPTeacher: https://github.com/teknium1/GPTeacher
- CAMELüê™: https://www.camel-ai.org/
- Human ChatGPT Comparison Corpus: https://github.com/Hello-SimpleAI/chatgpt-comparison-detection
- InstructionWild: https://github.com/XueFuzhao/InstructionWild

### Misc
- OIG: https://huggingface.co/datasets/laion/OIG
  - Superset of some of the datasets here
- HH-RLHF: https://huggingface.co/datasets/Anthropic/hh-rlhf
  - Contains human ratings of harmfulness and helpfulness of model outputs. The dataset contains ~160K human-rated examples, where each example in this dataset consists of a pair of responses from a chatbot, one of which is preferred by humans.
- OpenAI WebGPT: https://huggingface.co/datasets/openai/webgpt_comparisons
  - Includes a total of around 20K comparisons where each example comprises a question, a pair of model answers, and metadata. The answers are rated by humans with a preference score.
- OpenAI Summarization: https://huggingface.co/datasets/openai/summarize_from_feedback
  - Contains ~93K examples, each example consists of feedback from humans regarding the summarizations generated by a model. Human evaluators chose the superior summary from two options.



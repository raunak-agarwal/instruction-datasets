# Instruction Tuning Datasets
All available datasets for Instruction Tuning of Large Language Models

### Gold standard datasets (Originally meant for multi-task tuning)
- P3: https://github.com/bigscience-workshop/promptsource, https://huggingface.co/datasets/bigscience/P3
- Natural Instructions v2: https://github.com/allenai/natural-instructions
- The Flan Collection: https://github.com/google-research/FLAN/tree/main/flan/v2 (super set of some of the datasets here)
- CrossFit: https://github.com/INK-USC/CrossFit
- ExMix: https://arxiv.org/abs/2111.10952



### Generated using GPT 3.5/4

- Self-Instruct: https://github.com/yizhongw/self-instruct
- Unnatural Instructions: https://github.com/orhonovich/unnatural-instructions
- Alpaca: https://huggingface.co/datasets/tatsu-lab/alpaca
- Alpaca-Clean: https://github.com/gururise/AlpacaDataCleaned
- AlpacaGPT3.5Customized: https://huggingface.co/datasets/whitefox44/AlpacaGPT3.5Customized
- GPT4All: https://github.com/nomic-ai/gpt4all
- ShareGPT: https://huggingface.co/datasets/RyokoAI/ShareGPT52K
- GPTeacher: https://github.com/teknium1/GPTeacher
- CAMELüê™: https://www.camel-ai.org/
- InstructionWild: https://github.com/XueFuzhao/InstructionWild

### Misc
- OIG: https://huggingface.co/datasets/laion/OIG (super set of some of the datasets here)
- HH-RLHF: https://huggingface.co/datasets/Anthropic/hh-rlhf


